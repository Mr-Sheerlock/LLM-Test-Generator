{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import BertModel, BertForSequenceClassification, BertTokenizer\n",
    "import pandas as pd\n",
    "from preprocessing import Preprocess\n",
    "from tests import functions\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BertForLineClassification(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForLineClassification, self).__init__()\n",
    "        # self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.classifier = torch.nn.Linear(768, 8)  # 8 is the number of labels\n",
    "        # self.preprocessor = preprocessing.Preprocessor()\n",
    "        self.preprocessor = Preprocess()\n",
    "\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # pooled_output = outputs.pooler_output\n",
    "        pooled_output = self.dropout(input_tensor)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        return logits\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "def prepare_train_test_validation(option = None):\n",
    "    if(option == 'saif'):\n",
    "        # read DatasetMadeBySeif.xlsx \n",
    "        train = pd.read_excel('data/train.xlsx')\n",
    "        test  = pd.read_excel('data/test.xlsx')  \n",
    "        # print the first 5 rows of the data\n",
    "        \n",
    "        return train , test\n",
    "    # Prepare your train, test, and validation data here\n",
    "    # from data folder read data_train.parquet, data_test.parquet, and data_validation.L\n",
    "    data_train = pd.read_parquet('data/data_train_lines_combined.parquet')\n",
    "    data_test = pd.read_parquet('data/data_lines_test.parquet')\n",
    "    data_validation = pd.read_parquet('data/data_lines_val.parquet')\n",
    "    # lines is data column and lable is label column\n",
    "    train_data = data_train[['lines', 'label']]\n",
    "    test_data = data_test[['lines', 'label']]\n",
    "    validation_data = data_validation[['lines', 'label']]\n",
    "    return train_data, test_data\n",
    "    \n",
    "\n",
    "# Train the model\n",
    "def train(model, train_data, num_epochs=10, print_every=100, option = None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        num_samples = 0\n",
    "\n",
    "        for i, data in enumerate(train_data.iterrows()):\n",
    "            # Get line and label from data\n",
    "            if(option == 'saif'):\n",
    "                line = data[1]['code']\n",
    "                label = data[1]['label']\n",
    "            else:    \n",
    "                line = data[1]['lines']\n",
    "                label = data[1]['label']\n",
    "            if label == 1 or label == 2 or label == 3:\n",
    "                label = torch.tensor([1])\n",
    "            elif label == 4 or label == 5 or label == 6 or label == 7:\n",
    "                label = torch.tensor([2])\n",
    "            else:\n",
    "                label = torch.tensor([0])\n",
    "\n",
    "            # label = torch.tensor([label//3])\n",
    "\n",
    "\n",
    "            # Transform line to tensor using generate_line_embeddings method\n",
    "            line_tensor = model.preprocessor.generate_line_emdeddings(line)\n",
    "\n",
    "            # Train the model using line_tensor and label\n",
    "            logits = model(line_tensor)\n",
    "            loss = criterion(logits, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * label.size(0)\n",
    "            num_samples += label.size(0)\n",
    "\n",
    "            if (i + 1) % print_every == 0:\n",
    "                avg_loss = total_loss / num_samples\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Iteration [{i + 1}/{len(train_data)}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "        # Print statistics for the epoch\n",
    "        avg_loss = total_loss / num_samples\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "        #validate(model, validation_data)\n",
    "\n",
    "# Test the model\n",
    "\n",
    "def test(model, test_data , option = None):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    total_absolute_difference = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_data.iterrows():\n",
    "            if(option == 'saif'):\n",
    "                line = data[1]['code']\n",
    "                label = data[1]['label']\n",
    "            else:    \n",
    "                line = data[1]['lines']\n",
    "                label = data[1]['label']\n",
    "            if label == 1 or label == 2 or label == 3:\n",
    "                label = torch.tensor([1])\n",
    "            elif label == 4 or label == 5 or label == 6 or label == 7:\n",
    "                label = torch.tensor([2])\n",
    "            else:\n",
    "                label = torch.tensor([0])\n",
    "            # label = torch.tensor([label//3])\n",
    "\n",
    "            line_tensor = model.preprocessor.generate_line_emdeddings(line)\n",
    "            logits = model(line_tensor)\n",
    "            loss = criterion(logits, label)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            \n",
    "            predicted = predicted.item()\n",
    "            label = label.item()\n",
    "            all_labels.append(label)\n",
    "            all_predictions.append(predicted)\n",
    "            correct_predictions += (predicted == label)\n",
    "            total_samples += 1            \n",
    "            total_absolute_difference += abs(predicted - label)\n",
    "            \n",
    "            \n",
    "    average_loss = total_loss / len(test_data)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    accuracy_manual = correct_predictions / total_samples\n",
    "    precision = precision_score(all_labels, all_predictions, average='macro')\n",
    "    recall = recall_score(all_labels, all_predictions, average='macro')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='macro')\n",
    "    average_absolute_difference = total_absolute_difference / total_samples\n",
    "\n",
    "    \n",
    "    # calculate average of absolute difference between label and predicated\n",
    "    \n",
    "    print(f'Manual Accuracy: {accuracy_manual:.4f}')\n",
    "    print(f'Test Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "    print(f'Average Absolute Difference: {average_absolute_difference:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to save the model\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForLineClassification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = prepare_train_test_validation('saif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train(model, train_data, 5 , 1000, 'saif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Accuracy: 0.5287\n",
      "Test Loss: 11.4629, Accuracy: 0.5287\n",
      "Precision: 0.2643, Recall: 0.5000, F1 Score: 0.3458\n",
      "Average Absolute Difference: 0.4713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed Hussein\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test(model, test_data , 'saif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(model, 'bert_model.pth')\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'bert_model_generic_yarab.pth')\n",
    "\n",
    "\n",
    "# save the model in the same directory as the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForLineClassification(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_raw = BertForLineClassification()\n",
    "model_raw.load_state_dict(torch.load('bert_model_generic_2.pth'))\n",
    "model_raw.eval()  # Put the model in evaluation mode for inference\n",
    "# train model after load it \n",
    "# train(model_raw, train_data, validation_data, 5 , 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Accuracy: 0.9245\n",
      "Test Loss: 0.3722, Accuracy: 0.9245\n",
      "Precision: 0.2060, Recall: 0.2017, F1 Score: 0.2033\n",
      "Average Absolute Difference: 0.1657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mohamed Hussein\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Mohamed Hussein\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test(model_raw, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForLineClassification(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model_generic = BertForLineClassification()\n",
    "model_generic.load_state_dict(torch.load('bert_model_2.pth'))\n",
    "model_generic.eval()  # Put the model in evaluation mode for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_inference(lines_list, raw_labels, generic_labels):\n",
    "    print(len(lines_list), len(raw_labels), len(generic_labels))\n",
    "    for line, raw_label, generic_label in zip(lines_list, raw_labels, generic_labels):\n",
    "        print(f'Line: {line},  Label M1: {raw_label},  Label M2 : {generic_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infere(model,lines_tensor):\n",
    "    logits = model(lines_tensor)\n",
    "    _, predicted = torch.max(logits, 1)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def simple_function(var_0, var_2):\n",
      "    var_6 = \"SELECT * FROM products WHERE var_4=\" + \\\n",
      "        str(var_0) + \" AND var_5='\" + str(var_2) + \"'\"\n",
      "    var_6 += \"'; DROP TABLE users; --\"\n",
      "\n",
      "    var_1 = var_0 + var_2\n",
      "    os.system(\"echo Hello from the system!\")\n",
      "    if var_0 == 0:\n",
      "        print(\"var_0 is zero!\")\n",
      "    var_7 = var_0 * var_2\n",
      "    var_3 = eval(input(\"Enter an expression: \"))\n",
      "    return var_1, var_7\n",
      "\n",
      "def simple_function(var_0, var_2):\n",
      "    var_6 = \"SELECT * FROM products WHERE var_4=\" + \\\n",
      "        str(var_0) + \" AND var_5='\" + str(var_2) + \"'\"\n",
      "    var_6 += \"'; DROP TABLE users; --\"\n",
      "\n",
      "    var_1 = var_0 + var_2\n",
      "    os.system(\"echo Hello from the system!\")\n",
      "    if var_0 == 0:\n",
      "        print(\"var_0 is zero!\")\n",
      "    var_7 = var_0 * var_2\n",
      "    var_3 = eval(input(\"Enter an expression: \"))\n",
      "    return var_1, var_7\n",
      "\n",
      "13 13 13\n",
      "Line: def simple_function(var_0, var_2):,  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: var_6 = \"SELECT * FROM products WHERE var_4=\" + \\,  Label M1: tensor([4]),  Label M2 : tensor([4])\n",
      "Line: str(var_0) + \" AND var_5='\" + str(var_2) + \"'\",  Label M1: tensor([4]),  Label M2 : tensor([4])\n",
      "Line: var_6 += \"'; DROP TABLE users; --\",  Label M1: tensor([4]),  Label M2 : tensor([4])\n",
      "Line: ,  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: var_1 = var_0 + var_2,  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: os.system(\"echo Hello from the system!\"),  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: if var_0 == 0:,  Label M1: tensor([2]),  Label M2 : tensor([0])\n",
      "Line: print(\"var_0 is zero!\"),  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: var_7 = var_0 * var_2,  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: var_3 = eval(input(\"Enter an expression: \")),  Label M1: tensor([4]),  Label M2 : tensor([4])\n",
      "Line: return var_1, var_7,  Label M1: tensor([0]),  Label M2 : tensor([0])\n",
      "Line: ,  Label M1: tensor([0]),  Label M2 : tensor([0])\n"
     ]
    }
   ],
   "source": [
    "# print ( functions)\n",
    "lines_tensors =  model.preprocessor.generate_embeddings(functions[0])\n",
    "cleaned_func = model.preprocessor.clean_function_source(functions[0])\n",
    "# print(cleaned_func)\n",
    "# print(cleaned_func)\n",
    "raw_inference = []\n",
    "generic_inference = []\n",
    "# print(\"Inference results for model_raw : \")\n",
    "for tensor in lines_tensors:\n",
    "    raw_inference.append(infere(model_raw,tensor))\n",
    "    generic_inference.append(infere(model_generic,tensor))\n",
    "\n",
    "# print(\"Inference results for model_generic : \")\n",
    "# for tensor in lines_tensors:\n",
    "    \n",
    "parse_inference(cleaned_func, raw_inference, generic_inference)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import inspect\n",
    "def transform_to_generic_form(function_code):\n",
    "\n",
    "  function_code = inspect.getsource(simple_function)\n",
    "  def _replace_names(match):\n",
    "    name_type = match.group(1)  # Capture if it's a function (def/class) or variable\n",
    "    orig_name = match.group(2) if name_type else match.group(0)\n",
    "\n",
    "    if not name_type:  # Only replace variable names\n",
    "      generic_name = f\"VAR_{len(name_map) + 10}\"  # Start from VAR_10\n",
    "      name_map[orig_name] = generic_name\n",
    "      return generic_name\n",
    "\n",
    "    return match.group()  # Don't modify function names\n",
    "\n",
    "  name_map = {}  # Map original names to generic names\n",
    "\n",
    "  # Replace variable names with generic format\n",
    "  transformed_code = re.sub(r\"(def|class)\\s+(\\w+)\\b|\\b(\\w+)\\b\", _replace_names, function_code)\n",
    "\n",
    "  return transformed_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transform_to_generic_form(process_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
