{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SearchBasedBugFixing.utilsX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbugFixLogic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m bugFix\n",
      "File \u001b[0;32m~/BugFix/LLM-Test-Generator/SearchBasedBugFixing/bugFixLogic.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperatorsX\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mSearchBasedBugFixing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilsX\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Set, Dict, Callable\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SearchBasedBugFixing.utilsX'"
     ]
    }
   ],
   "source": [
    "# from bugFixLogic import bugFix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbugFixLogic_indexer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbugFix_indexer\u001b[39;00m\n",
      "File \u001b[0;32m~/BugFix/LLM-Test-Generator/SearchBasedBugFixing/bugFixLogic_indexer.py:31\u001b[0m\n\u001b[1;32m     29\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m model \u001b[38;5;241m=\u001b[39m UniXcoder(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/unixcoder-base\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#returns numpy array of embeddings\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# def get_embeddings(model,tokens,device=DEVICE):\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#   tokens_ids = model.tokenize([tokens],max_length=512,mode=\"<encoder-only>\")\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#   source_ids = torch.tensor(tokens_ids).to(device)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#   _,embeddings = model(source_ids)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#   return embeddings.detach()\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 500: named symbol not found"
     ]
    }
   ],
   "source": [
    "import bugFixLogic_indexer as bugFix_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [789774, 51515]]\n",
      "[[3], [841289]]\n",
      "No folder starting with 'FauxPy' found.\n",
      "File '2.txt' copied from 'testcases/BuggyPrograms' to 'testcases/GeneratedTests'.\n",
      "File 'test.py' created in 'testcases/GeneratedTests' with the converted Python code.\n",
      "returned from fault localization\n",
      "\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n",
      "0.63444114\n"
     ]
    }
   ],
   "source": [
    "bugFix_indexer.bugFix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[]], [[1, 2, 6, 72, 7, 33, 4]], [[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9, 3]], [[5, 4, 3, 2, 1]], [[5, 4, 3, 1, 2]]]\n",
      "[[[]], [[1, 2, 4, 6, 7, 33, 72]], [[1, 1, 2, 3, 3, 3, 4, 5, 5, 5, 6, 7, 8, 9, 9, 9]], [[1, 2, 3, 4, 5]], [[1, 2, 3, 4, 5]]]\n",
      "The folder 'FauxPyReport_SearchBasedBugFixing_sbfl_statement_2024_05_27_12_07_36_327068' has been deleted.\n",
      "File '10.txt' copied from 'testcases/BuggyPrograms' to 'testcases/GeneratedTests'.\n",
      "File 'test.py' created in 'testcases/GeneratedTests' with the converted Python code.\n",
      "returned from fault localization\n",
      "\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "************************************************************\n",
      "************************************************************\n",
      "2500\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        result = 0\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                result.append(left[i])\n",
      "                i += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                j += 2\n",
      "        i.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        result = mergesort(arr[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, arr)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] >= right[j]:\n",
      "                result.append(left[i])\n",
      "                arr += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                j += 0\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return arr\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        left = mergesort(arr[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = -1\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                middle.append(left[i])\n",
      "                middle += 1\n",
      "            else:\n",
      "                i.append(right[j])\n",
      "                j += 1\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        left = mergesort(arr[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                right.append(left[i])\n",
      "                j += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                j += 1\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        left = mergesort(arr[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, right) - 1\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                j.append(left[i])\n",
      "                i += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                j += 1\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return arr\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        middle = mergesort(arr[:middle])\n",
      "        middle = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        j = 0\n",
      "        while arr < len(left) and j < len(right):\n",
      "            if left[i] == right[j]:\n",
      "                result.append(left[i])\n",
      "                i += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                i += 1\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr - i) // 2\n",
      "        left = mergesort(arr[:middle])\n",
      "        right = mergesort(middle[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        result = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                result.append(left[i])\n",
      "                i += 1\n",
      "            else:\n",
      "                j.append(right[j])\n",
      "                result += 2\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        left = mergesort(arr[:middle])\n",
      "        i = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                result.append(left[i])\n",
      "                i += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                j += 2\n",
      "        result.extend(result[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        left = mergesort(left[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = 0\n",
      "        j = 0\n",
      "        while i < len(left) and j < len(right):\n",
      "            if left[i] <= right[j]:\n",
      "                result.append(left[i])\n",
      "                i += 0\n",
      "            else:\n",
      "                i.append(right[j])\n",
      "                j += 2\n",
      "        left.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == 0:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr) // 2\n",
      "        left = mergesort(arr[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n",
      "def mergesort(arr):\n",
      "\n",
      "    def merge(left, right):\n",
      "        result = []\n",
      "        i = -1\n",
      "        j = 0\n",
      "        while i < len(left) and j < right:\n",
      "            if left[i] <= right[j]:\n",
      "                result.append(left[i])\n",
      "                i += 1\n",
      "            else:\n",
      "                result.append(right[j])\n",
      "                j += 1\n",
      "        result.extend(left[i:] or right[j:])\n",
      "        return result\n",
      "    if len(arr) == -1:\n",
      "        return arr\n",
      "    else:\n",
      "        middle = len(arr + result) // 2\n",
      "        j = mergesort(arr[:middle])\n",
      "        right = mergesort(arr[middle:])\n",
      "        return merge(left, right)\n"
     ]
    }
   ],
   "source": [
    "bugFix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "index = faiss.read_index('../flatIP_index_all.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from unixcoder import UniXcoder\n",
    "import numpy as np\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "model = UniXcoder(\"microsoft/unixcoder-base\")\n",
    "model.to(DEVICE)\n",
    "\n",
    "#returns numpy array of embeddings\n",
    "def get_embeddings(model,tokens,device=DEVICE):\n",
    "  tokens_ids = model.tokenize([tokens],max_length=512,mode=\"<encoder-only>\")\n",
    "  source_ids = torch.tensor(tokens_ids).to(device)\n",
    "  _,embeddings = model(source_ids)\n",
    "  normEmb =  torch.nn.functional.normalize(embeddings, dim=1)\n",
    "  return normEmb.detach()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
